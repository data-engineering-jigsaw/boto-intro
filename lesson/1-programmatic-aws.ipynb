{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4171c1-4bb2-4301-9fff-60b2313fea02",
   "metadata": {},
   "source": [
    "# Programmatic AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee423d8-0707-4aa9-bb18-29a6f90ffabb",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219dcf5-e7cf-47f3-acc0-f16e0f0662bc",
   "metadata": {},
   "source": [
    "In this lesson, we'll see how we can work with AWS using the boto3 library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f52874-ccc5-4109-86c3-3374cc5aed19",
   "metadata": {},
   "source": [
    "### Starting with S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fca2e6-0aca-4d90-af73-543e26fca42b",
   "metadata": {},
   "source": [
    "The boto library is a python library that allows us to interact with aws resources in our account.\n",
    "\n",
    "Let's get started by working with the s3 resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfdd3f-0837-4cdb-85a4-54042aec51e8",
   "metadata": {},
   "source": [
    "You can get a sense of s3 by logging into aws, and then searching for s3 in the toolbar, and clicking on the s3 service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4efaa-ed64-4747-a07a-478079c8d657",
   "metadata": {},
   "source": [
    "<img src=\"./visit-s3.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63fd02-3719-4840-b025-320622215f79",
   "metadata": {},
   "source": [
    "From there, you'll see that s3 allows us to create these things called buckets -- which are just like folders -- and in that bucket we can store objects (ie. files).\n",
    "\n",
    "Get started by clicking on create bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace82af-b8ec-456b-af6d-97f9cedd64f0",
   "metadata": {},
   "source": [
    "<img src=\"./s3-buckets.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e9cea-991f-40eb-8169-499a7810bec5",
   "metadata": {},
   "source": [
    "And then let's create a new bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9f561-09c7-4efc-b0a3-9c637aae81e9",
   "metadata": {},
   "source": [
    "> Your bucket name will need to be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc78c3-1721-4ce8-8fc9-20f7e6bf4a61",
   "metadata": {},
   "source": [
    "<img src=\"./s3-create-bucket.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a368b4-f7aa-4e1b-96ff-e69a404a3cc1",
   "metadata": {},
   "source": [
    "Note that a bucket name must be unique across all of aws.  So you'll need to create a unique one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25687690-287e-40cb-83e3-fa1c76db9ce4",
   "metadata": {},
   "source": [
    "From there, click on your bucket, and you can drag and drop a file into the bucket and then click on the upload button."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af044bc-8e04-433c-b373-da49f56e71fd",
   "metadata": {},
   "source": [
    "<img src=\"./upload-file.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fabae-3a71-4657-96bc-46069c550ca3",
   "metadata": {},
   "source": [
    "> You can download the yelp lunch data [here](https://github.com/ledeprogram/courses/blob/master/foundations/mapping/tilemill/yelp-lunch-nyc.csv), if you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc17da-b5dd-40df-aa1a-33481c19a709",
   "metadata": {},
   "source": [
    "Ok, so we just uploaded some an object to an s3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bbbb6-09de-4038-a2d3-8bf298bae604",
   "metadata": {},
   "source": [
    "By default the bucket is not available to the public -- it's only available to the creator of the bucket and other users on the account.  (Under permissions, we could change this level of access, but we don't need to here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ecc65-7f50-4a1c-aead-c42aed07c9a1",
   "metadata": {},
   "source": [
    "### Access from the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10156d2f-b000-4b21-b49a-97db6bea8a3c",
   "metadata": {},
   "source": [
    "It turns out that we should be able to view both the bucket and the object from our command line.  Type in `aws s3 ls` from your terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf6dd5-9ab7-4b9c-885c-31f9f16b8e6c",
   "metadata": {},
   "source": [
    "You should see your bucket listed.  \n",
    "\n",
    "> Troubleshoot: If this did not work, you may have to take a look at the lessons on [setting up your aws account](https://colab.research.google.com/github/data-engineering-jigsaw/aws-iam/blob/main/index.ipynb) and [setting up the command line](https://colab.research.google.com/github/data-eng-10-21/aws-command-line/blob/main/2-aws-command-line.ipynb).\n",
    "\n",
    "Ok, so this worked because we previously called `aws configure` and then entered in our access key and secret access key.  Under ths hood, aws stored these credentials in a file on your computer located at `~/.aws/credentials`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1835c8-c6f2-4913-8953-ddc0f51b7312",
   "metadata": {},
   "source": [
    "<img src=\"./creds.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd027e43-02f8-4a5d-ab42-5f92e53640c4",
   "metadata": {},
   "source": [
    "### Working with Boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b517540-0ff3-4b68-9988-67e6cb8ecbdc",
   "metadata": {},
   "source": [
    "Ok, now enough of the AWS command line.  Let's move on to working with boto3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf5d1-59da-4c88-bbb1-ea456b35757a",
   "metadata": {},
   "source": [
    "We can get started by running `pip3 install boto3`, or installing via the `requirements.txt` file in the `src` directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04db775-f42d-4def-8d7e-54ee29cf6f6f",
   "metadata": {},
   "source": [
    "Now let's move through some of the methods for working with our s3 buckets.  \n",
    "\n",
    "> You do not need to know these too deeply, but it is good to just see what you can do through the boto library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6f8e9-ab9a-43e1-9148-2822f0c40027",
   "metadata": {},
   "source": [
    "### Reading from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d87a70-4b0a-4a64-977f-7b6af2eaf17a",
   "metadata": {},
   "source": [
    "In the `src/1_read_file.py` script you can see some methods for reading from s3.  Run these interactively with `python3 -i src/1_read_file.py`.  **Remember** that you'll have to change the bucket name you are reading from to match your bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512f210-6cfa-4c43-885a-b804474ebff6",
   "metadata": {},
   "source": [
    "Ok let's walk through some of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d29c1f-d7a9-4c82-834e-cb571996326d",
   "metadata": {},
   "source": [
    "> We connect with the s3 client."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bf6c1-3913-4a6c-a960-a706fbd7becd",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "import boto3\n",
    "# we can conntect to the s3 bucket with the following \n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# And from there, we can list all of the buckets we have access to\n",
    "\n",
    "s3.list_buckets()\n",
    "\n",
    "# If we want to list any of the individual files in a bucket, we can do so with the list objects method\n",
    "\n",
    "s3.list_objects(Bucket='jigsaw-initial-bucket')\n",
    "\n",
    "# And from there, we can get an individual object (or file)\n",
    "\n",
    "obj = s3.get_object(Bucket='jigsaw-initial-bucket', Key='yelp-lunch-nyc.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefad9c1-c44e-4641-8b6d-93db4e33d6dd",
   "metadata": {},
   "source": [
    "So notice that we identify a bucket with the `Bucket=` argument, and an object with the `Key=`.  From there, we can get the contents of the object with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52321efb-6696-4f76-8618-58ccbde6f3a9",
   "metadata": {},
   "source": [
    "```python\n",
    "obj['Body'].read()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb2863-1df4-422b-9d1f-21e7b4042ba8",
   "metadata": {},
   "source": [
    "### Write operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f248c-ad04-4440-a2c1-34a5f8cb5b43",
   "metadata": {},
   "source": [
    "Now let's move through some operations for creating buckets and then uploading objects to those buckets.\n",
    "\n",
    "> Follow along with this in the `2_write_bucket.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43a0be-8835-4abe-a9c5-e0df2ddafdb6",
   "metadata": {},
   "source": [
    "```python\n",
    "import boto3\n",
    "\n",
    "# Once again, we start by connecting to the s3 client\n",
    "s3 = boto3.client('s3') \n",
    "\n",
    "# Then we create a bucket with the following\n",
    "bucket = s3.create_bucket(Bucket = 'jigsaw-sample-json')\n",
    "# Again, we use the Bucket argument to specify the name of a bucket\n",
    "\n",
    "# Next, let's upload a file to our bucket.  We can do so with the s3.upload_file method.\n",
    "\n",
    "s3.upload_file('./yelp-lunch-nyc.csv', 'jigsaw-sample-json', 'lunch.csv')\n",
    "\n",
    "# So above we specify the local file we are uploading, then the name of the bucket we are uploading it to, and finally the name of the object (the key).  \n",
    "\n",
    "# From there, we can see if this was successful by getting our object, and then reading the contents of it.\n",
    "\n",
    "obj = s3.get_object(Bucket='jigsaw-sample-json', Key='lunch.csv')\n",
    "\n",
    "obj['Body'].read()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594050bf-a385-4c40-9dd1-ebcc3af5d4eb",
   "metadata": {},
   "source": [
    "### One last thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df782cf-e967-448c-bd5c-c43179e1acf3",
   "metadata": {},
   "source": [
    "Beyond uploading a file to s3, we can also just upload some of our data purely from python.  To do so, we can use the `s3.put_object` method.\n",
    "\n",
    "This time we specify the Body, Bucket and Key.\n",
    "\n",
    "> Whereas with our s3.upload_file method we specified the filename, bucket and key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889ac97-2253-4048-a184-cc94d63bc805",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "\n",
    "json_obj = {'hello': 'world'}\n",
    "\n",
    "s3.put_object(\n",
    "     Body=json.dumps(json_obj),\n",
    "     Bucket='jigsaw-sample-json',\n",
    "     Key='hello_world.json'\n",
    ")\n",
    "\n",
    "# Above we use json.dumps to convert our data to json, and then set that as the body, followed by the bucket we want to write to, and the name of our object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a6b5d-5af8-4b63-9eb2-b995c3a81b8c",
   "metadata": {},
   "source": [
    "From there, we can read our data from the bucket, and then use `json.loads` to convert from a json string back into the corresponding python data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5752f49-e0fa-4d68-8d6e-fd5a7ffd651f",
   "metadata": {},
   "source": [
    "```python\n",
    "obj = s3.get_object(Bucket='jigsaw-sample-json', Key='hello_world.json')\n",
    "\n",
    "text = obj['Body'].read()\n",
    "\n",
    "hello_world_dict = json.loads(text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29c461-b982-47d8-baed-e59d6b30e7f0",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cb0fe-4e61-4e62-b395-ce3e7d1d6bda",
   "metadata": {},
   "source": [
    "Ok, how's that for a whirlwind tour.  In this lesson, we started using the boto3 library to create both s3 buckets and objects, as well as read from those buckets and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d2e91-2aad-40ab-bd2f-739690c6169a",
   "metadata": {},
   "source": [
    "Here are some of the key methods.\n",
    "\n",
    "* Read\n",
    "```python\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3.list_objects(Bucket='jigsaw-initial-bucket')\n",
    "\n",
    "obj = s3.get_object(Bucket='jigsaw-initial-bucket', Key='yelp-lunch-nyc.csv')\n",
    "\n",
    "obj['Body'].read()\n",
    "```\n",
    "\n",
    "* Write\n",
    "\n",
    "```python\n",
    "bucket = s3.create_bucket(Bucket = 'jigsaw-sample-json')\n",
    "\n",
    "s3.upload_file('./yelp-lunch-nyc.csv', 'jigsaw-sample-json', 'lunch.csv')\n",
    "\n",
    "# upload some data\n",
    "json_obj = {'hello': 'world'}\n",
    "\n",
    "s3.put_object(\n",
    "     Body=json.dumps(json_obj),\n",
    "     Bucket='jigsaw-sample-json',\n",
    "     Key='hello_world.json'\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
